#!/usr/bin/env python3
"""
Test des optimisations de performance de CommuniConnect
"""

import requests
import json
import time
import statistics
from datetime import datetime
import concurrent.futures

# Configuration
BASE_URL = "http://127.0.0.1:8000/api"
LOGIN_URL = f"{BASE_URL}/users/login/"
POSTS_URL = f"{BASE_URL}/posts/"

def test_performance_optimizations():
    """Test des optimisations de performance"""
    
    print("ğŸš€ TEST DES OPTIMISATIONS DE PERFORMANCE")
    print("=" * 60)
    
    # 1. Connexion utilisateur
    print("\n1. Connexion utilisateur...")
    login_data = {
        "username": "testuser",
        "password": "testpass123"
    }
    
    try:
        response = requests.post(LOGIN_URL, json=login_data)
        if response.status_code == 200:
            token = response.json()['access']
            headers = {'Authorization': f'Bearer {token}'}
            print("âœ… Connexion rÃ©ussie")
        else:
            print(f"âŒ Erreur de connexion: {response.status_code}")
            return
    except Exception as e:
        print(f"âŒ Erreur de connexion: {str(e)}")
        return
    
    # 2. Test de performance des requÃªtes de posts
    print("\n2. Test de performance des requÃªtes de posts...")
    
    # Test sans cache (premiÃ¨re requÃªte)
    start_time = time.time()
    response = requests.get(POSTS_URL, headers=headers)
    first_request_time = time.time() - start_time
    
    if response.status_code == 200:
        posts_data = response.json()
        print(f"âœ… PremiÃ¨re requÃªte: {first_request_time:.3f}s ({len(posts_data.get('results', []))} posts)")
    else:
        print(f"âŒ Erreur premiÃ¨re requÃªte: {response.status_code}")
        return
    
    # Test avec cache (requÃªtes suivantes)
    cache_times = []
    for i in range(5):
        start_time = time.time()
        response = requests.get(POSTS_URL, headers=headers)
        cache_time = time.time() - start_time
        cache_times.append(cache_time)
        
        if response.status_code == 200:
            print(f"   RequÃªte {i+1}: {cache_time:.3f}s")
        else:
            print(f"âŒ Erreur requÃªte {i+1}: {response.status_code}")
    
    # Calcul des statistiques
    avg_cache_time = statistics.mean(cache_times)
    min_cache_time = min(cache_times)
    max_cache_time = max(cache_times)
    
    print(f"\nğŸ“Š Statistiques de performance:")
    print(f"   PremiÃ¨re requÃªte (sans cache): {first_request_time:.3f}s")
    print(f"   Temps moyen avec cache: {avg_cache_time:.3f}s")
    print(f"   Temps minimum avec cache: {min_cache_time:.3f}s")
    print(f"   Temps maximum avec cache: {max_cache_time:.3f}s")
    
    # Calcul de l'amÃ©lioration
    improvement = ((first_request_time - avg_cache_time) / first_request_time) * 100
    print(f"   AmÃ©lioration moyenne: {improvement:.1f}%")
    
    # 3. Test de charge concurrente
    print("\n3. Test de charge concurrente...")
    
    def make_request():
        """Fait une requÃªte simple"""
        try:
            response = requests.get(POSTS_URL, headers=headers, timeout=10)
            return response.status_code == 200
        except:
            return False
    
    # Test avec 10 requÃªtes simultanÃ©es
    concurrent_times = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        start_time = time.time()
        futures = [executor.submit(make_request) for _ in range(10)]
        results = [future.result() for future in futures]
        concurrent_time = time.time() - start_time
    
    success_count = sum(results)
    print(f"âœ… RequÃªtes simultanÃ©es: {success_count}/10 rÃ©ussies en {concurrent_time:.3f}s")
    
    # 4. Test de crÃ©ation de post avec invalidation de cache
    print("\n4. Test de crÃ©ation de post...")
    
    post_data = {
        "content": f"Test de performance - {datetime.now().strftime('%H:%M:%S')}",
        "post_type": "info",
        "is_anonymous": False
    }
    
    start_time = time.time()
    response = requests.post(POSTS_URL, json=post_data, headers=headers)
    creation_time = time.time() - start_time
    
    if response.status_code == 201:
        print(f"âœ… Post crÃ©Ã© en {creation_time:.3f}s")
        
        # Test de rÃ©cupÃ©ration aprÃ¨s crÃ©ation (cache invalidÃ©)
        start_time = time.time()
        response = requests.get(POSTS_URL, headers=headers)
        retrieval_time = time.time() - start_time
        
        if response.status_code == 200:
            print(f"âœ… RÃ©cupÃ©ration aprÃ¨s crÃ©ation: {retrieval_time:.3f}s")
        else:
            print(f"âŒ Erreur rÃ©cupÃ©ration: {response.status_code}")
    else:
        print(f"âŒ Erreur crÃ©ation post: {response.status_code}")
    
    # 5. Test de performance des dÃ©tails de post
    print("\n5. Test de performance des dÃ©tails de post...")
    
    if posts_data.get('results'):
        first_post_id = posts_data['results'][0]['id']
        post_detail_url = f"{POSTS_URL}{first_post_id}/"
        
        # Test sans cache
        start_time = time.time()
        response = requests.get(post_detail_url, headers=headers)
        detail_time = time.time() - start_time
        
        if response.status_code == 200:
            print(f"âœ… DÃ©tails post (sans cache): {detail_time:.3f}s")
            
            # Test avec cache
            start_time = time.time()
            response = requests.get(post_detail_url, headers=headers)
            cached_detail_time = time.time() - start_time
            
            if response.status_code == 200:
                print(f"âœ… DÃ©tails post (avec cache): {cached_detail_time:.3f}s")
                detail_improvement = ((detail_time - cached_detail_time) / detail_time) * 100
                print(f"   AmÃ©lioration dÃ©tails: {detail_improvement:.1f}%")
        else:
            print(f"âŒ Erreur dÃ©tails post: {response.status_code}")
    
    # 6. RÃ©sumÃ© des optimisations
    print("\n" + "=" * 60)
    print("ğŸ“ˆ RÃ‰SUMÃ‰ DES OPTIMISATIONS")
    print("=" * 60)
    
    print("âœ… Optimisations implÃ©mentÃ©es:")
    print("   â€¢ Cache Redis/Local pour les requÃªtes frÃ©quentes")
    print("   â€¢ Prefetch intelligent des relations")
    print("   â€¢ Annotations pour les compteurs")
    print("   â€¢ Invalidation automatique du cache")
    print("   â€¢ Index de base de donnÃ©es optimisÃ©s")
    print("   â€¢ Pagination des rÃ©sultats")
    print("   â€¢ Limitation des commentaires rÃ©cupÃ©rÃ©s")
    
    print("\nğŸ“Š AmÃ©liorations mesurÃ©es:")
    print(f"   â€¢ Temps de requÃªte rÃ©duit de {improvement:.1f}% en moyenne")
    print(f"   â€¢ Support de {success_count}/10 requÃªtes simultanÃ©es")
    print(f"   â€¢ Cache efficace pour les dÃ©tails de posts")
    
    print("\nğŸš€ Prochaines Ã©tapes recommandÃ©es:")
    print("   â€¢ Activer Redis en production")
    print("   â€¢ ImplÃ©menter la compression des rÃ©ponses")
    print("   â€¢ Ajouter un CDN pour les mÃ©dias statiques")
    print("   â€¢ Optimiser les requÃªtes de recherche")
    print("   â€¢ ImplÃ©menter un systÃ¨me de monitoring")

if __name__ == "__main__":
    test_performance_optimizations() 